{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "from dataclasses import dataclass\n",
    "from pycocotools.coco import COCO\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "\n",
    "def coco_to_xsys(segmentation):\n",
    "    return [(segmentation[i], segmentation[i + 1]) for i in range(0, len(segmentation), 2)]\n",
    "\n",
    "# import do script usado para detecção de veículos\n",
    "from parking_detector import ParkingSpace, Vehicle\n",
    "\n",
    "# modelo de detecção\n",
    "model = YOLO(\"yolov8x-seg.pt\")\n",
    "\n",
    "# categoria e id dos espaços de estacionamento\n",
    "parking_names = list(\"abcdef\")\n",
    "test_selection = [\n",
    "    [(381, 193), (377, 319), (502, 339), (486, 179), (396, 174)],\n",
    "    [(309, 142), (277, 245), (386, 300), (395, 152)],\n",
    "    [(248, 91), (203, 193), (282, 232), (329, 114)],\n",
    "    [(193, 54), (138, 155), (202, 185), (258, 75)],\n",
    "    [(149, 30), (78, 124), (136, 142), (205, 45)],\n",
    "    [(113, 4), (48, 70), (87, 97), (166, 21)],\n",
    "]\n",
    "\n",
    "# lista de objetos ParkingSpace\n",
    "parking_spaces = []\n",
    "\n",
    "# criação dos objetos ParkingSpace\n",
    "for space_id, space_name in enumerate(parking_names):\n",
    "    parking_spaces.append(ParkingSpace(space_id, test_selection[space_id]))\n",
    "\n",
    "path = Path(\"/home/ren/Downloads/carscoco/valid\")\n",
    "annotations_coco = COCO(path / \"_annotations.coco.json\")\n",
    "ann_data = annotations_coco.imgToAnns\n",
    "\n",
    "i = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "data = []\n",
    "for image in annotations_coco.imgs.values():\n",
    "    # valores reais\n",
    "    file_name = path / image[\"file_name\"]\n",
    "    id = image[\"id\"]\n",
    "    anns = ann_data[id]\n",
    "    cats_actual = [ann[\"category_id\"]-1 for ann in anns if ann['category_id']-1 != 6]\n",
    "    true_segs = {ann['category_id']-1: ann['segmentation'][0] for ann in anns if ann['category_id']-1 !=6}\n",
    "\n",
    "    # valores preditos pelo modelo\n",
    "    results = model(file_name, classes=[1, 2, 7])\n",
    "    car_seg_preds = results[0].masks.xy\n",
    "    vehicles = [\n",
    "        Vehicle(None, None, None, polygon=Polygon(mask)) for mask in car_seg_preds\n",
    "    ]\n",
    "    ordered_vehicles = [None]*6\n",
    "    for vehicle in vehicles:\n",
    "        for parking_space in parking_spaces:\n",
    "            if not parking_space.intersects(vehicle, threshold=0.3):\n",
    "                continue\n",
    "\n",
    "            ordered_vehicles[parking_space.id] = vehicle\n",
    "            if vehicle.cls_id is not None:\n",
    "                vehicle.cls_id = max(parking_space.id, vehicle.cls_id)\n",
    "                continue\n",
    "\n",
    "            vehicle.cls_id = parking_space.id\n",
    "    cats_predicted = [vehicle.cls_id for vehicle in ordered_vehicles if vehicle is not None]\n",
    "\n",
    "    for cat in range(len(parking_names)):\n",
    "        iou = None\n",
    "        if(cat not in cats_actual and cat not in cats_predicted):\n",
    "            continue\n",
    "        if cat in cats_actual and cat in cats_predicted:\n",
    "            true_seg = coco_to_xsys(true_segs[cat])\n",
    "            pol_actual = Polygon(true_seg)\n",
    "            pol_predicted = ordered_vehicles[cat].polygon\n",
    "            iou = pol_predicted.intersection(pol_actual).area/pol_predicted.union(pol_actual).area\n",
    "            wrong = wrong + 1 if iou < .3 else wrong\n",
    "            correct = correct + 1 if iou > .3 else correct\n",
    "        else:\n",
    "            wrong+=1\n",
    "\n",
    "        data.append({\n",
    "                        'ImageFileName': file_name,\n",
    "                        'ImageID': id,\n",
    "                        'catID': cat,\n",
    "                        'catName': parking_names[cat],\n",
    "                        'predicted': cat in cats_predicted,\n",
    "                        'actual': cat in cats_actual,\n",
    "                        'IOU': iou\n",
    "                    })\n",
    "    i+=1\n",
    "    print(f\"step {i} wrong {wrong} | total {correct+wrong} | acc {correct/(correct+wrong)}\")\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('catID')\n",
    "\n",
    "accuracy_per_cat = grouped.apply(lambda group: (group['predicted'] == group['actual']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('catName')\n",
    "\n",
    "def calculate_metrics(group):\n",
    "    total_instances = len(group)\n",
    "    correct_guesses = (group['predicted'] == group['actual']).sum()\n",
    "    wrong_guesses = total_instances - correct_guesses\n",
    "    accuracy = correct_guesses / total_instances if total_instances > 0 else 0.0\n",
    "    return pd.Series({\n",
    "        'Total': total_instances,\n",
    "        'Correto': correct_guesses,\n",
    "        'Errado': wrong_guesses,\n",
    "        'Acurácia': accuracy,\n",
    "        'Número de instâncias': total_instances,\n",
    "    })\n",
    "\n",
    "metrics_per_cat = grouped.apply(calculate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_cat.rename_axis(\"Vaga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_cat.Correto.sum()/metrics_per_cat.Total.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) \n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=metrics_per_cat.values, colLabels=metrics_per_cat.columns, cellLoc = 'center', loc='center')\n",
    "plt.savefig('metrics_table.png', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
